# Local AI Workspace Configuration
# Copy this file to .env and adjust values as needed.
# All settings are optional â€” defaults work out of the box.

# Ollama server URL (default: http://localhost:11434)
# LAW_OLLAMA_BASE_URL=http://localhost:11434

# Default chat model (must be pulled in Ollama first)
# LAW_DEFAULT_CHAT_MODEL=llama3

# Default embedding model
# LAW_DEFAULT_EMBEDDING_MODEL=nomic-embed-text

# Local data directory (all workspaces, DB, vectors stored here)
# LAW_DATA_DIR=~/.local-ai-workspace

# Chunking defaults
# LAW_CHUNK_SIZE=512
# LAW_CHUNK_OVERLAP=64

# RAG retrieval defaults
# LAW_TOP_K=5

# Generation defaults
# LAW_TEMPERATURE=0.7
# LAW_CONTEXT_WINDOW=4096

# Max file upload size in MB
# LAW_MAX_FILE_SIZE_MB=100

# Ollama API timeout in seconds
# LAW_API_TIMEOUT=120
